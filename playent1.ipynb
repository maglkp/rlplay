{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://medium.com/swlh/learning-with-deep-sarsa-openai-gym-c9a470d027a\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.cem import CEMAgent\n",
    "from rl.agents.sarsa import SARSAAgent\n",
    "from rl.memory import EpisodeParameterMemory\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import LinearAnnealedPolicy\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(13, 2)\n",
      "Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('gym_ent:ent-v1')\n",
    "\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "\n",
    "nb_actions = env.action_space.n\n",
    "obs_dim = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 108       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 108\n",
      "Trainable params: 108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Option 1 : Simple model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "sars = SARSAAgent(model=model, nb_actions=nb_actions, nb_steps_warmup=1000, train_interval=1)\n",
    "#sars = SARSAAgent(model=model, nb_actions=nb_actions, nb_steps_warmup=2000, train_interval=1)\n",
    "sars.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def __init__(self, nb_actions, memory, gamma=.99, batch_size=32, nb_steps_warmup=1000,\n",
    "#                  train_interval=1, memory_interval=1, target_model_update=10000,\n",
    "#                  delta_range=None, delta_clip=np.inf, custom_model_objects={}, **kwargs):\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# memory arg?\n",
    "#sars = DQNAgent(model=model, nb_actions=nb_actions, nb_steps_warmup=1000, train_interval=1)\n",
    "#sars.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sars = SARSAAgent(model=model, nb_actions=nb_actions, nb_steps_warmup=1000, train_interval=50)\n",
    "#sars = SARSAAgent(model=model, nb_actions=nb_actions, nb_steps_warmup=50, train_interval=1)\n",
    "sars.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "   76/10000 [..............................] - ETA: 6s - reward: -22.7105 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lkoziol/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 975us/step - reward: -8.8221\n",
      "752 episodes - episode_reward: -117.325 [-200.000, 31.400] - loss: 708.941 - mean_q: 0.890\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 10s 1ms/step - reward: -25.6267\n",
      "done, took 19.975 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc218d6c370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars.fit(env, nb_steps=20000, visualize=False, verbose=1)\n",
    "#sars.fit(env, nb_steps=200000, visualize=False, verbose=1)\n",
    "#sars.save_weights(f'sars_{ENV_NAME}_params.h5f', overwrite=True)\n",
    "# 100k 8min\n",
    "# 300k 25min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: -200.000, steps: 1\n",
      "Episode 2: reward: -197.650, steps: 3\n",
      "Episode 3: reward: -198.800, steps: 2\n",
      "Episode 4: reward: -198.800, steps: 2\n",
      "Episode 5: reward: -200.000, steps: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc218d6c1c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars.test(env, nb_episodes=10, visualize=True)\n",
    "# 8/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory = EpisodeParameterMemory(limit=2000, window_length=1)\n",
    "# cem = CEMAgent(model=model, nb_actions=nb_actions, memory=memory,\n",
    "#                batch_size=50, nb_steps_warmup=500, train_interval=1, elite_frac=0.05)\n",
    "# cem.compile()\n",
    "\n",
    "# cem.fit(env, nb_steps=10000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cem.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render(close=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
